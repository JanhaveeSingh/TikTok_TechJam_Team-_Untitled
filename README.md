# TikTok_TechJam - Team Untitled

## 007 : Enhanced GUI Automation System

### Table of Contents

* [Project Overview](#project-overview)
* [Key Innovation: Dynamic Completion Detection](#key-innovation-dynamic-completion-detection)
* [Performance Improvement Results](#performance-improvement-results)
* [APIs Used in the Project](#apis-used-in-the-project)

  * [External APIs](#external-apis)
  * [Internal Service APIs](#internal-service-apis)
* [Libraries Used in the Project](#libraries-used-in-the-project)
* [Technical Architecture](#technical-architecture)

  * [Dynamic Completion Detection System](#dynamic-completion-detection-system)
  * [Unified Parser System](#unified-parser-system)
  * [Multi-Modal Integration](#multi-modal-integration)
* [Performance Optimization Techniques](#performance-optimization-techniques)
* [Results and Impact](#results-and-impact)
* [Getting Started](#getting-started)
* [Contributors](#contributors)

---

### Problem Statement

With the explosive growth of mobile Internet and smart devices, GUIs are becoming increasingly complex and evolving rapidly. This drives the demand for high-quality application assurance. Manual testing is expensive, so automated GUI testing has become mainstream, especially for regression and compatibility testing.

However, most research in GUI automation with LLMs/MLLMs focuses only on **UI element localization**, leading to poor success rates in real-world dynamic scenarios.

---

### Project Overview

**007** is an advanced GUI automation system that improves **inference efficiency** through:

* **Dynamic state change detection**
* **Multi-modal parser integration**

Inspired by [AdaT](https://github.com/sidongfeng/AdaT/tree/main) and [AppAgentX](https://github.com/Westlake-AGI-Lab/AppAgentX), the system replaces fixed hardcoded timing with **adaptive completion detection**, enabling faster and more reliable workflows.

![Inspiration](assets/inspiration.png)

---

### Key Innovation: Dynamic Completion Detection

* **Before**: Fixed timers per workflow step (inefficient, sometimes too early/late).
* **Now**: Dynamic state change capture to detect when a step is truly complete.
* Inspired by AdaT‚Äôs adaptive testing approach.

---

### Performance Improvement Results

* **Workflow 1 (Google Maps: nearest coffee place)**

  * Before: 20.7s ‚Üí After: 10.47s (**49.4% faster**)

* **Workflow 2 (Google Maps: nearest restaurants)**

  * Before: 21.2s ‚Üí After: 9.06s (**57.3% faster**)


---

### APIs Used in the Project

#### External APIs

* OpenAI CLIP API ‚Äì Visual understanding
* Google Gemini API ‚Äì LLM reasoning & decision making
* Pinecone API ‚Äì Vector database
* Neo4j API ‚Äì Knowledge graph storage
* EasyOCR API ‚Äì Text recognition

#### Internal Service APIs

* OmniParser Service (Port 8000) ‚Äì High-accuracy YOLO-based parser
* CLIP Parser Service (Port 8002) ‚Äì Fast UI detection
* Feature Extractor Service (Port 8001) ‚Äì Embeddings
* Binary UI Classifier ‚Äì Completion detection

---

### Libraries Used in the Project
---
<p align="left">
  <!-- AI/ML -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pytorch/pytorch-original.svg" width="25"/>
  <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="25"/>
  <img src="https://avatars.githubusercontent.com/u/47238792?s=200&v=4" width="25"/>
  <img src="https://avatars.githubusercontent.com/u/72576348?s=200&v=4" width="25"/>
  <img src="https://avatars.githubusercontent.com/u/1728152?s=200&v=4" width="25"/> <!-- Faiss -->
  
  <!-- CV -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/opencv/opencv-original.svg" width="25"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="25"/>
  
  <!-- Web -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/fastapi/fastapi-original.svg" width="25"/>
  <img src="https://avatars.githubusercontent.com/u/73998423?s=200&v=4" width="25"/> <!-- Gradio -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/uvicorn/uvicorn-original.svg" width="25"/>
  
  <!-- DB -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/neo4j/neo4j-original.svg" width="25"/>
  <img src="https://avatars.githubusercontent.com/u/75007559?s=200&v=4" width="25"/> <!-- Pinecone -->
  <img src="https://avatars.githubusercontent.com/u/123345178?s=200&v=4" width="25"/> <!-- ChromaDB -->
  
  <!-- Mobile -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/android/android-original.svg" width="25"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/selenium/selenium-original.svg" width="25"/>
  
  <!-- NLP -->
  <img src="https://avatars.githubusercontent.com/u/126733545?s=200&v=4" width="25"/> <!-- LangChain -->
  <img src="https://avatars.githubusercontent.com/u/1342004?s=200&v=4" width="25"/> <!-- OpenAI -->
  <img src="https://avatars.githubusercontent.com/u/65625612?s=200&v=4" width="25"/> <!-- Google GenAI -->
  
  <!-- Utils -->
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/numpy/numpy-original.svg" width="25"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/pandas/pandas-original.svg" width="25"/>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="25"/>
</p>


| Category          | Library                                                            | Description               |
| ----------------- | ------------------------------------------------------------------ | ------------------------- |
| AI/ML             | torch, transformers, openai-clip, sentence-transformers, faiss-cpu | Core ML & embeddings      |
| Computer Vision   | opencv-python, pillow, easyocr                                     | Vision & OCR              |
| Web Frameworks    | fastapi, gradio, uvicorn                                           | Backend & demos           |
| Databases         | neo4j, pinecone-client, chromadb                                   | Graph & vector storage    |
| Mobile Automation | pure-python-adb, selenium                                          | Device/browser automation |
| NLP               | langchain, langgraph, langchain-openai, langchain-google-genai     | LLM integration           |
| Utilities         | numpy, pandas, dotenv, asyncio, aiohttp, lxml                      | Core utilities            |


---

### Technical Architecture

#### Dynamic Completion Detection System

```python
class AdaptiveWait:
    """
    Adaptive waiting system using AdaT's binary classification approach
    """
    def __init__(self, model_path=None, max_wait_time=5.0):
        self.classifier = BinaryUI(model_path)
        self.max_wait_time = max_wait_time
    
    def wait_for_completion(self, screenshot_func, description="action"):
        """Intelligently wait for UI action completion"""
        # Dynamic state monitoring instead of fixed timers
```

#### Unified Parser System

* **OmniParser (YOLO-based, high accuracy, slower)**
* **CLIP Parser (fast, memory tradeoff)**
* **Auto-switching**: Picks optimal parser based on context

#### Multi-Modal Integration

* CLIP for visual understanding
* AdaT classifier for completion detection
* FAISS for vector similarity search

---

### Performance Optimization Techniques

* **Dynamic State Monitoring** ‚Üí replace fixed timers with real-time detection
* **Parser Selection Strategy** ‚Üí OmniParser (accuracy) vs CLIP (speed)
* **Caching** ‚Üí vector caching for repeated recognition
* **Memory/Speed Tradeoff** ‚Üí CLIP uses more memory but accelerates inference

---

### Results and Impact

* **53.35% faster execution** on average
* Eliminates timing-related failures
* Optimizes resource usage (parser selection)
* Scales to complex workflows

---

### Getting Started

#### 1. Clone the Repository

```bash
git clone https://github.com/JanhaveeSingh/TikTok_TechJam_Team-_Untitled.git
```

#### 2. Create a Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate   # On Linux / Mac
venv\Scripts\activate      # On Windows
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Run the Demo

```bash
python demo.py
```

---

### Contributors

* üë©‚Äçüíª **Janhavee Singh** ‚Äì [@JanhaveeSingh](https://github.com/JanhaveeSingh)
* üë©‚Äçüíª **Rishika Mehta** - [@Oganesson0221](https://github.com/Oganesson0221)
* üë©‚Äçüíª **Yi Hsuen Cheng** ‚Äì [@yiihsuenn](https://github.com/yiihsuenn)
* üë©‚Äçüíª **Risha Sunil Shetty** ‚Äì [@RISHASUN001](https://github.com/RISHASUN001)
  
